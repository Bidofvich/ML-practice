{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face Mask Detection.ipynb",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJyO3PUbxG-6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import glob\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "import warnings\n",
        "# filter warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "import os\n",
        "print(os.listdir(\"../content/drive/My Drive/Colab Notebooks/mask\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2Y7s34uGwuy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten,GlobalAveragePooling2D\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D,MaxPool2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.optimizers import Adam,RMSprop\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5f0NjZzxj34",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "test='/content/drive/My Drive/Colab Notebooks/mask/test'\n",
        "train='/content/drive/My Drive/Colab Notebooks/mask/train'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRPy-wwz0U0W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_width, img_height = 128,128\n",
        "nb_train_samples = 3594\n",
        "nb_validation_samples = 858\n",
        "batch_size = 30\n",
        "\n",
        "from keras import backend as K\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    input_shape = (3, img_width, img_height)\n",
        "else:\n",
        "    input_shape = (img_width, img_height, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1uDRlIonofI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    test,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJe-958AHQlr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras.layers import Activation, Dense, Flatten, Dropout,BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras import backend as K\n",
        "\n",
        "model = Sequential()\n",
        "model=Sequential()\n",
        "model.add(Conv2D(filters=8,kernel_size=(5,5),padding=\"Same\",activation=\"relu\",input_shape=(128,128,3)))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "#model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(filters=16,kernel_size=(4,4),padding=\"Same\",activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "#model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(filters=32,kernel_size=(4,4),padding=\"Same\",activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Conv2D(filters=48,kernel_size=(4,4),padding=\"Same\",activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512,activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2,activation=\"softmax\"))\n",
        "#defining optimizer\n",
        "optimizer=Adam(lr=0.0001,beta_1=0.9,beta_2=0.999)\n",
        "#compile the model\n",
        "model.compile(optimizer=optimizer,loss=\"binary_crossentropy\",metrics=[\"acc\"])\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=30,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRimJB7QTA3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history['acc'],'r')\n",
        "plt.plot(history.history['val_acc'],'g')\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training accuracy', 'Validation accuracy'], loc='lower right')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9O0HrRE-TDb3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history['val_loss'],'r')\n",
        "plt.plot(history.history['loss'],'b')\n",
        "\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.grid()\n",
        "plt.legend(['Training loss', 'Validation loss'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6azaVxOTGTe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"/content/drive/My Drive/Lab1/assignment/Threshold/mask.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1s8ISbkUr6w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.mobilenet import preprocess_input\n",
        "import numpy as np\n",
        "model= load_model('/content/drive/My Drive/Lab1/assignment/Threshold/mask.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0ENaB1LV6p6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = image.load_img('/content/drive/My Drive/yolov3/mask/talh.jpg', target_size=(128,128))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "img_data = preprocess_input(x)\n",
        "classes = model.predict(img_data)\n",
        "print(classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIE7CYi2XWW7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "faceCascade = cv2.CascadeClassifier(\"/content/drive/My Drive/Colab Notebooks/mask/haarcascade_frontalface_alt2.xml\")\n",
        "model = load_model(\"/content/drive/My Drive/Lab1/assignment/Threshold/mask.h5\")\n",
        "\n",
        "def face_mask_detector(frame):\n",
        "  # frame = cv2.imread(fileName)\n",
        "  gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "  faces = faceCascade.detectMultiScale(gray,\n",
        "                                        scaleFactor=1.1,\n",
        "                                        minNeighbors=5,\n",
        "                                        minSize=(60, 60),\n",
        "                                        flags=cv2.CASCADE_SCALE_IMAGE)\n",
        "  faces_list=[]\n",
        "  preds=[]\n",
        "  for (x, y, w, h) in faces:\n",
        "      face_frame = frame[y:y+h,x:x+w]\n",
        "      face_frame = cv2.cvtColor(face_frame, cv2.COLOR_BGR2RGB)\n",
        "      face_frame = cv2.resize(face_frame, (128, 128))\n",
        "      face_frame = img_to_array(face_frame)\n",
        "      face_frame = np.expand_dims(face_frame, axis=0)\n",
        "      face_frame =  preprocess_input(face_frame)\n",
        "      faces_list.append(face_frame)\n",
        "      if len(faces_list)>0:\n",
        "          preds = model.predict(faces_list)\n",
        "      for pred in preds:\n",
        "          (mask, withoutMask) = pred\n",
        "      label = \"Mask\" if mask > withoutMask else \"No Mask\"\n",
        "      color = (0, 255, 0) if label == \"Mask\" else (0, 0, 255)\n",
        "      label = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\n",
        "      cv2.putText(frame, label, (x, y- 10),\n",
        "                  cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
        "\n",
        "      cv2.rectangle(frame, (x, y), (x + w, y + h),color, 3)\n",
        "  # cv2_imshow(frame)\n",
        "  return frame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHTUqvnkYAZs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_image = cv2.imread(\"/content/Mask227.jpeg\")\n",
        "output = face_mask_detector(input_image)\n",
        "cv2_imshow(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZBcKPWVcZI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}